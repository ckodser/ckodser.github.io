<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Scaling Latent Reasoning via Looped Language Models | Arshia Soltani Moakhar </title> <meta name="author" content="Arshia Soltani Moakhar"> <meta name="description" content="Training a recurrent reasoning model. Looping the same models over and over again."> <meta name="keywords" content="academic-website, research, Arshia Soltani Moakhar, ckodser, adversarial training, OOD detection, Interpretability"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?16404ec2cd2689e8d0f38f73fe0d38f9"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon3.ico?ed0664bb8b662bf21b84ddd264d8c2a9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ckodser.github.io/summaries/Scaling_Latent_Reasoning_via_Looped_Language_Models/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class=" sticky-bottom-footer collection-summaries"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="//"> <span class="font-weight-bold">Arshia</span> Soltani Moakhar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item active"> <a class="nav-link" href="/summaries/">Summaries <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Scaling Latent Reasoning via Looped Language Models</h1> <p class="post-description">Training a recurrent reasoning model. Looping the same models over and over again.</p> <a href="https://arxiv.org/pdf/2510.25741v2" style="display: inline-block; padding: 8px 0; font-weight: 500; text-decoration: none; border-bottom: 2px solid transparent; transition: border-color 0.3s ease; background: linear-gradient(135deg, #5e72e4, #ff7eb3); -webkit-background-clip: text; background-clip: text; -webkit-text-fill-color: transparent;" onmouseover="this.style.borderBottom='2px solid #ff7eb3'" onmouseout="this.style.borderBottom='2px solid transparent'" target="_blank" rel="noopener noreferrer">Read Paper →</a> </header> <article> <p>The core of the method is a recurrent architecture with a learned mechanism for adaptive computation depth.</p> <h3 id="looplm-architecture">LoopLM Architecture</h3> <p>The fundamental idea of LoopLM is to reuse a stack of \(L\) Transformer layers multiple times. A standard non-looped Transformer’s forward pass is \(F(\cdot) := \text{lmhead} \circ M^L \circ \text{emb}(\cdot)\), where \(M^L\) is the composition of \(L\) layers. The LoopLM applies this stack \(t\) times, where \(t\) is the number of recurrent steps or “loops”:</p> \[F^{(t)}(\cdot) = \text{lmhead} \circ \underbrace{M^L \circ M^L \circ \dots \circ M^L}_{t \text{ iterations}} \circ \text{emb}(\cdot)\] <p>At each recurrent step \(t \in \{1, \dots, T_{\text{max}}\}\), the model produces an output and computes a standard cross-entropy loss for next-token prediction:</p> \[\mathcal{L}^{(t)} = \mathbb{E}_{x_{1:M}} \left[ \sum_{l=1}^{M-1} -\log p_\theta^{(t)}(x_{l+1} \mid x_{1:l}) \right]\] <p>where \(h^{(t)}\) is the hidden state after \(t\) loops.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Scaling_Latent_Reasoning_via_Looped_Language_Models/image1.png" sizes="95vw"></source> <img src="/assets/img/Scaling_Latent_Reasoning_via_Looped_Language_Models/image1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="adaptive-computation-via-gating-mechanism">Adaptive Computation via Gating Mechanism</h3> <p>To allow the model to dynamically choose the number of recurrent steps \(t\) for a given input, an “exit gate” is introduced. This gate operates in parallel with the language model head at each step.</p> <ol> <li> <p><strong>Instantaneous Exit Probability:</strong> At each step \(t\), the gate computes an exit probability \(\lambda_t(x)\) based on the final-layer hidden state \(h^{(t)}\): \(\lambda_t(x) = \sigma(\text{Linear}_\phi(h^{(t)})) \in (0, 1)\) where \(\phi\) are the gate parameters.</p> </li> <li> <p><strong>Exit Distribution:</strong> These per-step probabilities are combined to form a valid discrete probability distribution \(p_\phi(t \mid x)\) over the exit steps \(\{1, \dots, T_{\text{max}}\}\). The probability of not exiting in the first \(t\) steps (survival probability) is \(S_t(x) = \prod_{j=1}^t (1 - \lambda_j(x))\). The probability of exiting at step \(t\) is then: \(p_\phi(t \mid x) = \begin{cases} \lambda_t(x) S_{t-1}(x) &amp; \text{if } t &lt; T_{\text{max}} \\ S_{T_{\text{max}}-1}(x) &amp; \text{if } t = T_{\text{max}} \end{cases}\) This ensures that \(\sum_{t=1}^{T_{\text{max}}} p_\phi(t\mid x) = 1\).</p> </li> <li> <p><strong>Inference:</strong> During inference, a quantile-based policy is used. Given a threshold \(q \in [0, 1]\), the model exits at the first step \(m\) where the cumulative distribution function \(\text{CDF}(m\lvert x) = \sum_{t=1}^m p_{\phi}(t \rvert x)\) exceeds \(q\).</p> </li> </ol> <h3 id="two-stage-training-objective">Two-Stage Training Objective</h3> <p>The model and the gating mechanism are trained in two stages.</p> <h4 id="stage-i-entropy-regularized-objective">Stage I: Entropy-Regularized Objective</h4> <p>During pre-training, the model is trained with an objective that combines the expected task loss across all steps with an entropy regularizer for the exit distribution. The total loss \(\mathcal{L}\) is:</p> \[\mathcal{L} = \underbrace{\sum_{t=1}^{T_{\text{max}}} p_\phi(t\mid x) \mathcal{L}^{(t)}}_{\text{expected task loss}} - \underbrace{\beta H(p_\phi(\cdot\mid x))}_{\text{entropy regularization}}\] <p>where \(H(p_\phi(\cdot\lvert x)) = - \sum_{t=1}^{T_{\text{max}}} p_\phi(t \rvert x) \log p_\phi(t\mid x)\) is the entropy of the exit distribution. The coefficient \(\beta\) balances the trade-off between task performance and encouraging the model to explore different computation depths.</p> <h4 id="stage-ii-focused-adaptive-gate-training">Stage II: Focused Adaptive Gate Training</h4> <p>After the main pre-training, the LM parameters are frozen, and only the exit gate parameters \(\phi\) are fine-tuned. This stage trains the gate to make termination decisions based on realized performance improvements.</p> <ol> <li> <p><strong>Loss Improvement Signal:</strong> The improvement in the (detached) per-token loss from step \(t-1\) to \(t\) is calculated: \(I_i^{(t)} = \max(0, \mathcal{L}_{i, \text{stop}}^{(t-1)} - \mathcal{L}_{i, \text{stop}}^{(t)})\)</p> </li> <li> <p><strong>Ideal Continuation Probability:</strong> This improvement signal is converted into a soft target label \(w_i^{(t)} \in [0,1]\) indicating whether to continue (\(w_i^{(t)} \approx 1\)) or exit (\(w_i^{(t)} \approx 0\)): \(w_i^{(t)} = \sigma(k \cdot (I_i^{(t)} - \gamma))\) where \(k\) is a slope parameter and \(\gamma\) is a threshold.</p> </li> <li> <p><strong>Adaptive Loss:</strong> The gate is trained using a binary cross-entropy loss to match its continuation probability, \(1 - \lambda_i^{(t)}\), to the ideal label \(w_i^{(t)}\): \(\mathcal{L}_{\text{adaptive}}^{(t)} = -\frac{1}{M} \sum_{i=1}^M \left[ w_i^{(t)} \log(1 - \lambda_i^{(t)}) + (1 - w_i^{(t)}) \log(\lambda_i^{(t)}) \right]\)</p> </li> </ol> <h3 id="training-pipeline-and-stability-measures">Training Pipeline and Stability Measures</h3> <ul> <li> <strong>Recurrent Step Reduction:</strong> Initial experiments with 8 recurrent steps showed instability (loss spikes). The number of steps was reduced to 4 for the main training phases to balance computational depth and stability.</li> <li> <strong>Stability-Driven Upcycling:</strong> To create the 2.6B model from a 24-layer checkpoint, layers were duplicated to 48. The recurrent structure makes this upcycling process smoother than in standard Transformers.</li> <li> <strong>KL Divergence Coefficient Reduction:</strong> The coefficient \(\beta\) was reduced from 0.1 to 0.05 in later stages to decrease conflicting gradients between the task loss and the KL penalty, allowing the model to learn more natural depth patterns.</li> </ul> <h3 id="efficient-inference-with-kv-cache-sharing">Efficient Inference with KV Cache Sharing</h3> <p>A naive implementation of LoopLM would require a separate KV cache for each of the \(T_{\text{max}}\) recurrent steps, leading to a \(T_{\text{max}}\)-fold increase in memory usage. The paper investigates KV cache sharing strategies during the auto-regressive decoding phase.</p> <ul> <li> <strong>Finding:</strong> While dedicated KV caches are necessary during the prompt processing (prefill) phase, they can be shared during token generation.</li> <li> <strong>Method:</strong> Reusing only the KV cache from the <strong>final (4th) recurrent step</strong> or an <strong>averaged KV cache</strong> across all steps results in minimal performance degradation while reducing the memory footprint by 4x, making the models practical for deployment. Using the first-step cache leads to a catastrophic performance collapse.</li> </ul> <p>Here they give it away that during inference they always compute 4 recurents even if the model generates the token in the first recurrence.</p> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"ckodser/ckodser.github.io","data-repo-id":"R_kgDOHfm8sw","data-category":"General","data-category-id":"DIC_kwDOHfm8s84ClE4O","data-mapping":"pathname","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":"light","data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © 2026 Arshia Soltani Moakhar. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/summary_image_expand.js?de7a891220c8fc9ce98add9ca26b742e"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams",inlineMath:[["$","$"],["\\(","\\)"]],processEscapes:!0}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="module" src="/assets/js/search/ninja-keys.min.js?f8abf2f636f242d077f24149a0a56c96"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"My Research Projects",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-summaries",title:"Summaries",description:"Paper summaries",section:"Navigation",handler:()=>{window.location.href="/summaries/"}},{id:"projects-data-leakage-of-lora-in-federated-training",title:"Data Leakage of LoRA in federated training",description:"This article highlights the potential risks of reconstructing private data from the gradients shared in Federated Learning, especially when using the LoRA finetuning technique.",section:"Projects",handler:()=>{window.location.href="/projects/Attention_is_all_you_need_to_attack/"}},{id:"projects-basedon",title:"BasedOn",description:"Using Learnable If Statements for Interpretability",section:"Projects",handler:()=>{window.location.href="/projects/BasedOn/"}},{id:"projects-sparsity-for-interpretability",title:"sparsity for interpretability",description:"Leveraging sample sparsity to improve interpretability of neural networks",section:"Projects",handler:()=>{window.location.href="/projects/SPADE/"}},{id:"projects-certified-robust-neural-network",title:"Certified Robust Neural Network",description:"Certify Robustness using median neurons",section:"Projects",handler:()=>{window.location.href="/projects/sparse_L_inf_network/"}},{id:"summaries-a-mathematical-framework-for-transformer-circuits",title:"A Mathematical Framework for Transformer Circuits",description:"In Transformers residual stream is the main object and layers read and write from/to it.",section:"Summaries",handler:()=>{window.location.href="/summaries/A_Mathematical_Framework_for_Transformer_Circuits/"}},{id:"summaries-an-overview-of-early-vision-in-inceptionv1",title:"An Overview of Early Vision in InceptionV1",description:"inceptionV1 feature maps of different layers",section:"Summaries",handler:()=>{window.location.href="/summaries/An_Overview_of_Early_Vision_in_InceptionV1/"}},{id:"summaries-clip-dissect-automatic-description-of-neuron-representations",title:"CLIP-Dissect Automatic Description of Neuron Representations",description:"Find concepts that activates a neuron using a image dataset",section:"Summaries",handler:()=>{window.location.href="/summaries/CLIP-Dissect_Automatic_Description_of_Neuron_Representations_in_Deep_Vision_Networks/"}},{id:"summaries-can-large-language-models-explain-their-internal-mechanisms",title:"Can Large Language Models Explain Their Internal Mechanisms?",description:"summary of Can Large Language Models Explain Their Internal Mechanisms?",section:"Summaries",handler:()=>{window.location.href="/summaries/Can_Large_Language_Models_Explain_Their_Internal_Mechanisms/"}},{id:"summaries-dash-detection-and-assessment-of-systematic-hallucinations-of-vlms",title:"DASH Detection and Assessment of Systematic Hallucinations of VLMs",description:"Make a dataset that VLMs hallucinate and wrongly think things exist in images",section:"Summaries",handler:()=>{window.location.href="/summaries/DASH_Detection_and_Assessment_of_Systematic_Hallucinations_of_VLMs/"}},{id:"summaries-deep-learning-is-not-so-mysterious-or-different",title:"Deep Learning is Not So Mysterious or Different",description:"??",section:"Summaries",handler:()=>{window.location.href="/summaries/Deep_Learning_is_Not_So_Mysterious_or_Different/"}},{id:"summaries-emergent-world-representations-exploring-a-sequence-model-trained-on-a-synthetic-task",title:"Emergent World Representations Exploring a Sequence Model Trained on a Synthetic Task",description:"summary of Emergent World Representations  Exploring a Sequence Model Trained on a Synthetic Task",section:"Summaries",handler:()=>{window.location.href="/summaries/Emergent_World_Representations_Exploring_a_Sequence_Model_Trained_on_a_Synthetic_Task/"}},{id:"summaries-every-decision-tree-has-an-influential-variable",title:"Every decision tree has an influential variable",description:"title is self-explanatory",section:"Summaries",handler:()=>{window.location.href="/summaries/Every_decision_tree_has_an_influential_variable/"}},{id:"summaries-interpretability-beyond-feature-attribution-quantitative-testing-with-concept-activation-vectors-tcav",title:"Interpretability Beyond Feature Attribution Quantitative Testing with Concept Activation Vectors (TCAV)",description:"summary of Interpretability Beyond Feature Attribution  Quantitative Testing with Concept Activation Vectors (TCAV)",section:"Summaries",handler:()=>{window.location.href="/summaries/Interpretability_Beyond_Feature_Attribution_Quantitative_Testing_with_Concept_Activation_Vectors_(TCAV)/"}},{id:"summaries-llm-latent-reasoning-as-chain-of-superposition",title:"LLM Latent Reasoning as Chain of Superposition",description:"Train an encoder that summarizes reasoning chunks. Then train a latent reasoning model on the summaries it produces from some CoT data.",section:"Summaries",handler:()=>{window.location.href="/summaries/LLM_Latent_Reasoning_as_Chain_of_Superposition/"}},{id:"summaries-llms-are-single-threaded-reasoners-demystifying-the-working-mechanism-of-soft-thinking",title:"LLMs are Single-threaded Reasoners, Demystifying the Working Mechanism of Soft Thinking",description:"Vanilla Soft Thinking pushes the model to the greedy token sampling internally. They showed that the model usually continues to work only with the most probable next token. To mitigate this issue they suggest adding noise to logits and get better performance.",section:"Summaries",handler:()=>{window.location.href="/summaries/LLMs_are_Single-threaded_Reasoners_Demystifying_the_Working_Mechanism_of_Soft_Thinking/"}},{id:"summaries-labeling-neural-representations-with-inverse-recognition",title:"Labeling Neural Representations with Inverse Recognition",description:"summary of Labeling Neural Representations with Inverse Recognition",section:"Summaries",handler:()=>{window.location.href="/summaries/Labeling_Neural_Representations_with_Inverse_Recognition/"}},{id:"summaries-learning-decision-trees-from-random-examples",title:"Learning decision trees from random examples",description:"Decision tree learning By Finding Consistent Decision Trees",section:"Summaries",handler:()=>{window.location.href="/summaries/Learning_decision_trees_from_random_examples/"}},{id:"summaries-leveraged-volume-sampling-for-linear-regression",title:"Leveraged volume sampling for linear regression",description:"Active Learning in linear regression with multiplicative error rate bounds",section:"Summaries",handler:()=>{window.location.href="/summaries/Leveraged_volume_sampling_for_linear_regression/"}},{id:"summaries-multiplex-thinking-reasoning-via-token-wise-branch-and-merge",title:"Multiplex Thinking Reasoning via Token wise Branch and Merge",description:"Make soft-thinking a bit random. Then train with GRPO.",section:"Summaries",handler:()=>{window.location.href="/summaries/Multiplex_Thinking_Reasoning_via_Token_wise_Branch_and_Merge/"}},{id:"summaries-physics-of-language-models",title:"Physics of Language Models",description:"Understanding LLMs by training smaller LMs in controlled environment",section:"Summaries",handler:()=>{window.location.href="/summaries/Physics_of_LM/"}},{id:"summaries-progress-measures-for-grokking-via-mechanistic-interpretability",title:"Progress measures for grokking via mechanistic interpretability",description:"summary of Progress measures for grokking via mechanistic interpretability",section:"Summaries",handler:()=>{window.location.href="/summaries/Progress_measures_for_grokking_via_mechanistic_interpretability/"}},{id:"summaries-properly-learning-decision-trees-in-almost-polynomial-time",title:"Properly learning decision trees in almost polynomial time",description:"learning a decision tree for unifrom random data distribution in O(s ^ log(log(s)))",section:"Summaries",handler:()=>{window.location.href="/summaries/Properly_learning-_decision_trees_in_almost_polynomial_time/"}},{id:"summaries-reasoning-within-the-mind-dynamic-multimodal-interleaving-in-latent-space",title:"Reasoning Within the Mind Dynamic Multimodal Interleaving in Latent Space",description:"Training-free latent reasoning. Optimize latent reasoning tokens to maximize model confidence, which correlates with accuracy.",section:"Summaries",handler:()=>{window.location.href="/summaries/Reasoning_Within_the_Mind_Dynamic_Multimodal_Interleaving_in_Latent_Space/"}},{id:"summaries-scaling-latent-reasoning-via-looped-language-models",title:"Scaling Latent Reasoning via Looped Language Models",description:"Training a recurrent reasoning model. Looping the same models over and over again.",section:"Summaries",handler:()=>{window.location.href="/summaries/Scaling_Latent_Reasoning_via_Looped_Language_Models/"}},{id:"summaries-scaling-monosemanticity-extracting-interpretable-features-from-claude-3-sonnet",title:"Scaling Monosemanticity Extracting Interpretable Features from Claude 3 Sonnet",description:"Scale SAE to Claude 3 Sonnet",section:"Summaries",handler:()=>{window.location.href="/summaries/Scaling_Monosemanticity_Extracting_Interpretable_Features_from_Claude_3_Sonnet/"}},{id:"summaries-soft-tokens-hard-truths",title:"Soft Tokens, Hard Truths",description:"They add Gaussian noise to the soft-thinking embeddings, then train with RL using RLOO.",section:"Summaries",handler:()=>{window.location.href="/summaries/Soft_Tokens_Hard_Truths/"}},{id:"summaries-top-down-induction-of-decision-trees-rigorous-guarantees-and-inherent-limitations",title:"Top-down induction of decision trees- rigorous guarantees and inherent limitations",description:"greedily learn a decision tree based on the most inflouential variables in all leaves.",section:"Summaries",handler:()=>{window.location.href="/summaries/Top_down_induction_of_decision_trees_rigorous_guarantees_and_inherent_limitations/"}},{id:"summaries-towards-monosemanticity-decomposing-language-models-with-dictionary-learning",title:"Towards Monosemanticity Decomposing Language Models With Dictionary Learning",description:"How SAE works",section:"Summaries",handler:()=>{window.location.href="/summaries/Towards_Monosemanticity_Decomposing_Language_Models_With_Dictionary_Learning/"}},{id:"summaries-what-do-we-learn-from-inverting-clip-models",title:"What do we learn from inverting CLIP models?",description:"summary of What do we learn from inverting CLIP models?",section:"Summaries",handler:()=>{window.location.href="/summaries/What_do_we_learn_from_inverting_CLIP_models/"}},{id:"summaries-zoom-in-an-introduction-to-circuits",title:"Zoom In An Introduction to Circuits",description:"Investigate Vision Circuits by Studying the Connections between Neurons",section:"Summaries",handler:()=>{window.location.href="/summaries/Zoom_In_An_Introduction_to_Circuits/"}},{id:"summaries-active-learning-survey",title:"Active Learning Survey",description:"Active Learning for Agnostic classification",section:"Summaries",handler:()=>{window.location.href="/summaries/active-survey/"}},{id:"summaries-the-true-sample-complexity-of-active-learning",title:"The True Sample Complexity of Active Learning",description:"A different definition of active learning label complexity",section:"Summaries",handler:()=>{window.location.href="/summaries/true-active/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61%72%73%68%69%61.%73%6F%6C%74%61%6E%69%32@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=2H6Wl4MAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/ckodser","_blank")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>