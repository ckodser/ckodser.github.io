<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>They first want to train an encoder that summarizes the reasoning till a checkpoint. They call it <code class="language-plaintext highlighter-rouge">enc</code>.</p> <p>Assume we have question $X$ and a reasoing chain that we split into some chunks $S_i$. So the whole thing look like this $[X,S_0,S_1,\cdots,S_N, Ans]$. The encoder should get the input $[X,S_0,S_1,\cdots,S_i,L]$ and produce a summary we name $Z_i$. This $Z_i$ should have this property that we can replace that chunks with $Z_i$ and the <code class="language-plaintext highlighter-rouge">LLM</code> can still continue the reasoning chain. So the LLM should be able to produce $[S_{i+1}, S_{i+2}, \cdots, S_n, Ans]$ given the $[X, Z_0, Z_1, \cdots, Z_i]$. This is considered a good summary.</p> <p>They first argue that these $Z_i$s should lie in the linear space of the input token embeddings. Since the <code class="language-plaintext highlighter-rouge">LLM</code> only know how to interpret that space. (Section 3). SO they designed <code class="language-plaintext highlighter-rouge">enc</code> to produce logits normaly given the $[X,S_0,S_1,\cdots,S_i,L]$ and then the $Z_i$ is the linear combination of the predicted tokens.</p> <h1 id="training-the-enc-and-llm-models">Training the enc and LLM models</h1> <table> <tbody> <tr> <td>To train these models they use the following loss: $$\ell_{\text{sup}} = \frac{1}{N} \sum_{i=1}^{N} \frac{1}{</td> <td>J_i</td> <td>} \sum_{t \in J_i} (-\log p_{\theta}(x_t</td> <td>\mathcal{I}_i; \text{LTSuM}))$$.</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>$J_i$ is the set of index of tokens in chunk $i$. $N$ is the total number of chunks. and $p_{\theta_{LLM}}(x_t</td> <td>\mathcal{I}_i; \text{LTSuM}))$ is the probability that models gives the correct token $x_t$ given the previous summarise. $[X, z_0, z_1, \cdots, z_i]$. So it measures how well the model predicts the future tokens given $Z_i$-s. Note that i this phase the model is not given the previous chunks actual text, but only the summary.</td> </tr> </tbody> </table> <p>However $\theta_{enc}$ is used to generate $Z_i$s given the previous context. So to generate $L_i$ the model sees $X, S_0, \cdots, S_i$, but not any $L_i$.</p> <p>So $In the above loss we have two different models <code class="language-plaintext highlighter-rouge">enc</code> and <code class="language-plaintext highlighter-rouge">LLM</code> involved but they have seperate cahce and everything. The only way <code class="language-plaintext highlighter-rouge">enc</code> effects that loss it trough $Z_i$s.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/LLM_Latent_Reasoning_as_Chain_of_Superposition/image2.png" sizes="95vw"></source> <img src="/assets/img/LLM_Latent_Reasoning_as_Chain_of_Superposition/image2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h1 id="training-a-latent-reasoning-model-using-z_is">Training a latent reasoning model using $Z_i$s</h1> <p>They then use <code class="language-plaintext highlighter-rouge">enc</code> to compress/translate some CoT data (problem + reasoning + answer) to $[X, Z_0, \cdots, Z_N, Ans]$ format. They also save the $\alpha_i$ that generated those $Z_i$. These $\alpha_i$ will be used as the target of the latent reasoning model.</p> <p>The way they trained the model is that they used normal SFT loss for explicit part and some other loss for latent part.</p> \[L_{\text{auto}}(\theta_{\text{llm}}) = L_{exp}(\theta_{\text{llm}}) + L_{lat}(\theta_{\text{llm}}).\] <p>We have</p> \[L_{exp}(\theta_{\text{llm}}) = \frac{1}{|S_{\text{exp}}|} \sum_{t \in S_{\text{exp}}} (-\log q_t[y_t])\] <p>This is normal SFT on normal data.</p> <p>For latent part they add some noise to $\alpha_i$ like this: $\tilde{p}_t = \text{softmax} \left( \log \alpha_t + g_t \right) \quad g_t \sim \text{Gumbel}(0, 1)$. They then do some what normal SFT on them.</p> \[L_{lat}(\theta_{\text{llm}}) = \frac{1}{|S_{\text{lat}}|} \sum_{t \in S_{\text{lat}}} \mathbb{E}_{\mathbf{g}} \left[ \text{KL}(\tilde{p}_t(\mathbf{g}) \,\|\, \mathbf{q}_t) \right]\] <h1 id="model-compereses-a-reasoning-path">Model compereses a reasoning path</h1> <p>In this part their figures and arguments are reasonable. They show that in the top 50 tokens in the $\alpha_i$ they have many tokens of $S_i$. They have $1.169$ on average when each chunk have two tokens, and $2.385$ on average when each chunk have 4 tokens. So it is reasonable to assume that the model is doing the same reasoning path but faster.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/LLM_Latent_Reasoning_as_Chain_of_Superposition/image3.png" sizes="95vw"></source> <img src="/assets/img/LLM_Latent_Reasoning_as_Chain_of_Superposition/image3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h1 id="model-doing-multiple-reasoing-path">Model doing multiple reasoing path</h1> <p>They manually made several reasoning path for GSM8K problems.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/LLM_Latent_Reasoning_as_Chain_of_Superposition/image4.png" sizes="95vw"></source> <img src="/assets/img/LLM_Latent_Reasoning_as_Chain_of_Superposition/image4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>They measure how much the latent reasoning path intersect with these different paths and calcualte a sum like thing. They showed this value is larger than 1.7 for most samples. They try to argue this is the numbre of parallel reasoning paths the model follow.</p> </body></html>