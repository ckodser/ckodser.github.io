<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Active Learning Survey | Arshia Soltani Moakhar </title> <meta name="author" content="Arshia Soltani Moakhar"> <meta name="description" content="Active Learning for Agnostic classification"> <meta name="keywords" content="academic-website, research, Arshia Soltani Moakhar, ckodser, adversarial training, OOD detection, Interpretability"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?16404ec2cd2689e8d0f38f73fe0d38f9"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon3.ico?ed0664bb8b662bf21b84ddd264d8c2a9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ckodser.github.io/summaries/active-survey/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class=" sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="//"> <span class="font-weight-bold">Arshia</span> Soltani Moakhar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item active"> <a class="nav-link" href="/summaries/">Summaries <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Active Learning Survey</h1> <p class="post-description">Active Learning for Agnostic classification</p> <a href="https://web.ics.purdue.edu/~hanneke/docs/active-survey/active-survey.pdf" style="display: inline-block; padding: 8px 0; font-weight: 500; text-decoration: none; border-bottom: 2px solid transparent; transition: border-color 0.3s ease; background: linear-gradient(135deg, #5e72e4, #ff7eb3); -webkit-background-clip: text; background-clip: text; -webkit-text-fill-color: transparent;" onmouseover="this.style.borderBottom='2px solid #ff7eb3'" onmouseout="this.style.borderBottom='2px solid transparent'" target="_blank" rel="noopener noreferrer">Read Paper →</a> </header> <article> <h1> Conceptual Themes </h1> <p>They used an example to explain that in active learning we are facing two different scenarios which one of them is very hard for active learning. In the hard scenario the label complexity of active learning is very high and the only thing differentiate between these two scenario is the target function. Therefore, when they report label complexity of algorithms it is usually based on properties of target function.</p> <p>The example is as follows: Assume our data is 1D data points with binary labels and ew want to learn an interval such that the classifier assigns + to the datapoints inside the interval and - to the datapoints outside of the interval.</p> <p>They argue that if target function is all -, then it is very hard for us to find the best interval. The only info we have is that the best interval doesn’t include any point we already check its label. So no matter how many samples we use and check their label we are not able to return the best classifier.</p> <h1> Definitions </h1> <ol> <li>For any classifier \(h\), define \(er(h) = P_{XY} ((x, y) : h(x) \neq y)\), called the error rate;</li> <li>Define \(\nu = \inf_{h\in C} er(h)\)</li> <li>Algorithm \(A\), achieves label complexity \(\Lambda\) if, for every integer \(n \geq \Lambda(\epsilon, \delta,P_{XY} )\), if \(h\) is the classifier produced by running \(A\) with budget \(n\), then with probability at least \(1 − \delta\), \(er(h) \leq \epsilon\).</li> <li>Define \(d = vc(C)\)</li> <li>Define the \(\epsilon\)-ball centered at \(h\) as \(B_{C,P}(h, \epsilon) = {g \in C : P(x : g(x) \neq h(x)) \leq \epsilon}\)</li> <li>Define the region of disagreement of \(H\) as \(DIS(C) = {x \in X : \exists_{h,g \in C} s.t. h(x) \neq g(x)}\)</li> <li>Define the disagreement coefficient of \(h\) with respect to \(C\) under \(P\) as \(\theta_h (r_0) = \max(\sup_{r&gt;r_0} \frac{P(DIS(B (h, r)))}{r}, 1)\).</li> <li>Define \(\theta(r_0) = \theta_{f^*}(r_0)\).</li> <li>Condition 2.3. For some \(a \in [1, \infty)\) and \(\alpha \in [0, 1]\), for every \(h \in C\), \(P(x : h(x) \neq f^*(x)) \leq a (er(h) − er(f^*))^{\alpha}\).</li> </ol> <h1> Passive Learning </h1> <p>In noisy case we have</p> <p><strong>Theorem 3.4.</strong> The passive learning algorithm ERM(C, .) achieves a label complexity \(\Lambda\) such that, for any distribution \(P_{XY}\), \(\forall \epsilon, \delta \in (0, 1)\),</p> \[\Lambda(\nu + \epsilon, \delta, P_{XY}) \leq \frac{\epsilon+\nu}{\epsilon^2} \left( d \log \left( \theta(\nu + \epsilon) \right) + \log \left( \frac{1}{\delta} \right) \right)\] <p>and for the case with \(a, \alpha\) we have</p> \[\Lambda(\nu + \epsilon, \delta, P_{XY}) \leq a \left( \frac{1}{\epsilon} \right)^{2 - \alpha} \left( d \log \left( \theta \left( a \epsilon^{\alpha} \right) \right) + \log \left( \frac{1}{\delta} \right) \right).\] <h2> Lower bounds of passive learning </h2> <p>there exists a distribution \(P_{XY}\) for which \(er(f^*) = \nu\) and</p> <p>\(\Lambda(\nu + \epsilon, \delta, P_{XY}) \geq \Omega\left(\frac{\nu+\epsilon}{\epsilon^2}(d+\log(1/\delta))\right)\).</p> <p>Furthermore, for \(a ,\alpha\), and sufficiently small \(\epsilon, \delta &gt; 0\), there exists a distribution \(P_{XY}\) with these values of \(a, \alpha\), such that</p> <p>\(\Lambda(\nu + \epsilon, \delta, P_{XY}) \geq \Omega\left(a\left(\frac{1}{\epsilon}\right)^{2-\alpha}(d+\log(1/\delta))\right)\).</p> <h1> Lower bounds of active learning </h1> <p>There exists a universal constant \(q \in (0, \infty)\) such that, if \(\\lvert C \\rvert \geq 3\), then for any label complexity \(\Lambda\) achieved by an active learning algorithm, for any \(\nu \in (0, 1/2)\) and sufficiently small \(\epsilon, \delta &gt; 0\), there exists a distribution \(P_{XY}\) with \(er(f^*) = \nu\) such that</p> \[\Lambda(\nu + \epsilon, \delta, P_{XY}) \geq q \frac{\nu^2}{\epsilon^2} (d + \log(1/\delta)).\] <p>Furthermore, for any \(a \in [4, \infty), \alpha \in (0, 1]\), and sufficiently small \(\epsilon, \delta &gt; 0\), there exists a distribution \(P_{XY}\) satisfying Condition 2.3 (in fact, satisfying (2.1) or (2.2), for \(\alpha &lt; 1\) or \(\alpha = 1\), respectively) with these values of a and \(\alpha\), such that</p> \[\Lambda(\nu + \epsilon, \delta, P_{XY}) \geq q a^2 \left( \frac{1}{\epsilon} \right)^{2 - 2\alpha} (d + \log(1/\delta)).\] <h1> Disagreement-Based Active Learning </h1> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/active-survey/img_1.png" sizes="95vw"></source> <img src="/assets/img/active-survey/img_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>where \(U\) is defined by</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/active-survey/img_2.png" sizes="95vw"></source> <img src="/assets/img/active-survey/img_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>They introduced RobustCAL which is similar to \(A^2\) algorithm. It achieves this bound,</p> <p>\(\Lambda(\nu + \epsilon, \delta, P_{XY}) \leq \theta(\nu + \epsilon) \left(\frac{\nu^2}{\epsilon^2} + \log (\frac{1}{\epsilon})\right) \left(d \log (\theta(\nu + \epsilon)) + \log(\frac{\log (\frac{1}{\delta})}{\delta})\right)\).</p> <p>or</p> \[\Lambda(\nu + \epsilon, \delta,P_{XY}) \leq a^2 \theta \left( a \epsilon^{\alpha} \right) \left( \frac{1}{\epsilon} \right)^{2 - 2\alpha} \left( d \log \left( \theta \left( a \epsilon^{\alpha} \right) \right) + \log \left( \frac{\log (a/\epsilon)}{\delta} \right) \right) \log \left( \frac{1}{\epsilon} \right),\] <p>Note that we have \(\theta(r_0) \leq \frac{1}{r_0}\).</p> <p>The normal analysis of \(A^2\) algorithm have \(\theta(\nu + \epsilon)^2\) instead of \(\theta(\nu + \epsilon)\) but some works shows that a very small changes in \(A^2\) can achieve this bound.</p> <h1> Bounding the Disagreement Coefficient </h1> <p>Some properties of Disagreement Coefficient</p> <p>Let \(\epsilon \in (0, \infty)\) and \(c \in (1, \infty)\). Then \(\theta_h(\epsilon/c) \leq c\theta_h(\epsilon)\) and \(\theta_h(\epsilon)/c \leq \theta_h(c\epsilon)\).</p> <p>They also show that \(\theta_h(\epsilon) = O(1)\) is equal to \(\theta_h(0) &lt; \infty\),</p> <p>Second Theorem is about changing distribution a little bit.</p> <p>Let \(\lambda \in (0, 1)\), and suppose \(P\) and \(P_0\) are distributions over \(X\) such that \(\lambda P_0 \leq P \leq (1/\lambda)P_0\). For all \(\epsilon &gt; 0\), let \(\theta_h(\epsilon)\) and \(\theta_0^h(\epsilon)\) denote the disagreement coefficients of \(h\) with respect to \(C\) under \(P\) and \(P_0\), respectively. Then \(\forall \epsilon &gt; 0\),</p> \[\theta_0^h(\lambda \epsilon) \lambda^2 \leq \theta_h(\epsilon) \leq \frac{\theta_0^h(\epsilon/\lambda)}{\lambda^2}\] <p>Third Theorem is about merging to distribution.</p> <p>Suppose there exist \(\lambda \in (0, 1)\) and distributions \(P^{'}\) and \(P^{"}\) over \(X\) such that \(P = \lambda P^{'} + (1 - \lambda) P^{"}\). For \(\epsilon &gt; 0\), let \(\theta_h(\epsilon), \theta^{'}_h(\epsilon),\) and \(\theta^{"}_h(\epsilon)\) denote the disagreement coefficients of \(h\) with respect to \(C\) under \(P, P^{'},\) and \(P^{"}\), respectively. Then \(\forall \epsilon &gt; 0\),</p> \[\theta_h(\epsilon) \leq \theta^{'}_h(\epsilon/\lambda) + \theta^{"}_h(\epsilon/(1 - \lambda))\] <p>Fourth Theorem is about Merging two classification sets</p> <p>Let \(C^{'}\) and \(C^{"}\) be sets of classifiers such that \(C = C^{'}\cup C^{"}\), and let \(P\) be a distribution over \(X\). For all \(\epsilon &gt; 0\), let \(\theta_h(\epsilon), \theta^{'}_h(\epsilon),\) and \(\theta^{"}_h(\epsilon)\) denote the disagreement coefficients of \(h\) with respect to \(C, C^{'}\), and \(C^{"},\) respectively, under \(P\). Then \(\forall\epsilon &gt; 0\),</p> \[\max \left\{ \theta^{'}_h(\epsilon), \theta^{"}_h(\epsilon) \right\} \leq \theta_h(\epsilon) \leq \theta^{'}_h(\epsilon) + \theta^{"}_h(\epsilon) + 2\] <p>The most interesting Lemma is</p> <p><strong>Lemma 7.12.</strong> \(\theta_h(\epsilon) = o(1/\epsilon) \iff \Pr \left( \lim_{r \to 0} DIS(B_h(h, r)) \right) = 0.\)</p> <h2> Discrete Distribution </h2> <p>every discrete distribution P has \(\theta_h(\epsilon) = o(\frac{1}{\epsilon})\).</p> <p>The proof uses this lemma which is very easy to prove.</p> <p><strong>Lemma 7.13.</strong> \(\forall r \in [0, 1], \quad DIS(B(h, r)) \subseteq \left\{x : P(\{x\}) \leq r\right\}\)</p> <p><strong>Theorem 7.14.</strong> If \(\exists\{x_i\}_{i\in\mathbb{N}}\) in \(X\) such that \(P(\{x_i : i \in \mathbb{N}\}) = 1\), then \(\theta_h(\epsilon) = o(1/\epsilon).\)</p> <h2> Asymptotic Behavior </h2> <p>In this section they say lets discuss \(P(DIS(B (h, r_0)))\) directly rater than $\theta_h(r_0) = \sup_{r&gt;r_0} \frac{P(DIS(B (h, r)))}{r}$.</p> <p>They proved these theorems which are easy to understand.</p> <p><strong>Corollary 7.10.</strong> \(\theta_h(\epsilon) = O(1)\) if and only if \(P(DIS(B(h, \epsilon))) = O(\epsilon)\).</p> <p><strong>Definition 7.11.</strong> For any classifier \(h\) and set of classifiers \(H\), define the disagreement core of \(h\) with respect to \(H\) under \(P\) as \(\partial_{H} h = \lim_{r\to 0} DIS(B_{H}(h, r))\).</p> <p><strong>Lemma 7.12.</strong> \(\theta_h(\epsilon) = o(1/\epsilon)\) if and only if \(P(\partial_{H} h) = 0\).</p> <p><strong>Lemma 7.13.</strong> For all \(r\in [0, 1]\), \(DIS(B(h, r)) \subseteq \{x : P(\{x\}) \leq r\}\).</p> <h2> Linear Separators </h2> <p>In this case, we find \(\theta_h(\epsilon) = o(1/ \epsilon)\) is guaranteed as long as $P$ has a density; the stronger \(\theta_h(\epsilon) = O(1)\) guarantee is obtained as long as the density is bounded, has bounded support, and the separating hyperplane of \(h\) passes through the support at a continuity point of the density.</p> <p>The assumptions seems very reasonable.</p> <h2> Axis-aligned Rectangles </h2> <p>This is like interval learning but in a higher dimension. Assume we have space with \(k\) dimensions.</p> <p>Hanneke found that a certain noise-robust halving-style active learning algorithm achieves a label complexity that, if \(p = P(x : f(x) = +1) &gt; 5\nu\), is</p> \[\frac{k^3}{p}\left(\frac{\nu^2}{\epsilon^2} + 1 \right) \text{polylog} \left(\frac{k}{\epsilon \delta p}\right)\] <p>Also if \(P\) the uniform distribution over \([0, 1]^k\), then</p> \[\limsup_{\epsilon \to 0} \frac{P(DIS(B(h, \epsilon)))}{\epsilon} &lt; k\] <p>They also show that</p> \[\theta_h(\epsilon) \leq \frac{k^3}{p} \cdot \text{polylog} \left(\frac{k}{p \epsilon}\right).\] </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"ckodser/ckodser.github.io","data-repo-id":"R_kgDOHfm8sw","data-category":"General","data-category-id":"DIC_kwDOHfm8s84ClE4O","data-mapping":"pathname","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":"light","data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © 2026 Arshia Soltani Moakhar. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams",inlineMath:[["$","$"],["\\(","\\)"]],processEscapes:!0}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="module" src="/assets/js/search/ninja-keys.min.js?f8abf2f636f242d077f24149a0a56c96"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"My Research Projects",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-summaries",title:"Summaries",description:"Paper summaries",section:"Navigation",handler:()=>{window.location.href="/summaries/"}},{id:"projects-data-leakage-of-lora-in-federated-training",title:"Data Leakage of LoRA in federated training",description:"This article highlights the potential risks of reconstructing private data from the gradients shared in Federated Learning, especially when using the LoRA finetuning technique.",section:"Projects",handler:()=>{window.location.href="/projects/Attention_is_all_you_need_to_attack/"}},{id:"projects-basedon",title:"BasedOn",description:"Using Learnable If Statements for Interpretability",section:"Projects",handler:()=>{window.location.href="/projects/BasedOn/"}},{id:"projects-sparsity-for-interpretability",title:"sparsity for interpretability",description:"Leveraging sample sparsity to improve interpretability of neural networks",section:"Projects",handler:()=>{window.location.href="/projects/SPADE/"}},{id:"projects-certified-robust-neural-network",title:"Certified Robust Neural Network",description:"Certify Robustness using median neurons",section:"Projects",handler:()=>{window.location.href="/projects/sparse_L_inf_network/"}},{id:"summaries-a-mathematical-framework-for-transformer-circuits",title:"A Mathematical Framework for Transformer Circuits",description:"In Transformers residual stream is the main object and layers read and write from/to it.",section:"Summaries",handler:()=>{window.location.href="/summaries/A_Mathematical_Framework_for_Transformer_Circuits/"}},{id:"summaries-an-overview-of-early-vision-in-inceptionv1",title:"An Overview of Early Vision in InceptionV1",description:"inceptionV1 feature maps of different layers",section:"Summaries",handler:()=>{window.location.href="/summaries/An_Overview_of_Early_Vision_in_InceptionV1/"}},{id:"summaries-clip-dissect-automatic-description-of-neuron-representations",title:"CLIP-Dissect Automatic Description of Neuron Representations",description:"Find concepts that activates a neuron using a image dataset",section:"Summaries",handler:()=>{window.location.href="/summaries/CLIP-Dissect_Automatic_Description_of_Neuron_Representations_in_Deep_Vision_Networks/"}},{id:"summaries-can-large-language-models-explain-their-internal-mechanisms",title:"Can Large Language Models Explain Their Internal Mechanisms?",description:"summary of Can Large Language Models Explain Their Internal Mechanisms?",section:"Summaries",handler:()=>{window.location.href="/summaries/Can_Large_Language_Models_Explain_Their_Internal_Mechanisms/"}},{id:"summaries-dash-detection-and-assessment-of-systematic-hallucinations-of-vlms",title:"DASH Detection and Assessment of Systematic Hallucinations of VLMs",description:"Make a dataset that VLMs hallucinate and wrongly think things exist in images",section:"Summaries",handler:()=>{window.location.href="/summaries/DASH_Detection_and_Assessment_of_Systematic_Hallucinations_of_VLMs/"}},{id:"summaries-emergent-world-representations-exploring-a-sequence-model-trained-on-a-synthetic-task",title:"Emergent World Representations Exploring a Sequence Model Trained on a Synthetic Task",description:"summary of Emergent World Representations  Exploring a Sequence Model Trained on a Synthetic Task",section:"Summaries",handler:()=>{window.location.href="/summaries/Emergent_World_Representations_Exploring_a_Sequence_Model_Trained_on_a_Synthetic_Task/"}},{id:"summaries-every-decision-tree-has-an-influential-variable",title:"Every decision tree has an influential variable",description:"title is self-explanatory",section:"Summaries",handler:()=>{window.location.href="/summaries/Every_decision_tree_has_an_influential_variable/"}},{id:"summaries-interpretability-beyond-feature-attribution-quantitative-testing-with-concept-activation-vectors-tcav",title:"Interpretability Beyond Feature Attribution Quantitative Testing with Concept Activation Vectors (TCAV)",description:"summary of Interpretability Beyond Feature Attribution  Quantitative Testing with Concept Activation Vectors (TCAV)",section:"Summaries",handler:()=>{window.location.href="/summaries/Interpretability_Beyond_Feature_Attribution_Quantitative_Testing_with_Concept_Activation_Vectors_(TCAV)/"}},{id:"summaries-llm-latent-reasoning-as-chain-of-superposition",title:"LLM Latent Reasoning as Chain of Superposition",description:"Train an encoder that summarizes reasoning chunks. Then train a latent reasoning model on the summaries it produces from some CoT data.",section:"Summaries",handler:()=>{window.location.href="/summaries/LLM_Latent_Reasoning_as_Chain_of_Superposition/"}},{id:"summaries-labeling-neural-representations-with-inverse-recognition",title:"Labeling Neural Representations with Inverse Recognition",description:"summary of Labeling Neural Representations with Inverse Recognition",section:"Summaries",handler:()=>{window.location.href="/summaries/Labeling_Neural_Representations_with_Inverse_Recognition/"}},{id:"summaries-learning-decision-trees-from-random-examples",title:"Learning decision trees from random examples",description:"Decision tree learning By Finding Consistent Decision Trees",section:"Summaries",handler:()=>{window.location.href="/summaries/Learning_decision_trees_from_random_examples/"}},{id:"summaries-leveraged-volume-sampling-for-linear-regression",title:"Leveraged volume sampling for linear regression",description:"Active Learning in linear regression with multiplicative error rate bounds",section:"Summaries",handler:()=>{window.location.href="/summaries/Leveraged_volume_sampling_for_linear_regression/"}},{id:"summaries-physics-of-language-models",title:"Physics of Language Models",description:"Understanding LLMs by training smaller LMs in controlled environment",section:"Summaries",handler:()=>{window.location.href="/summaries/Physics_of_LM/"}},{id:"summaries-progress-measures-for-grokking-via-mechanistic-interpretability",title:"Progress measures for grokking via mechanistic interpretability",description:"summary of Progress measures for grokking via mechanistic interpretability",section:"Summaries",handler:()=>{window.location.href="/summaries/Progress_measures_for_grokking_via_mechanistic_interpretability/"}},{id:"summaries-properly-learning-decision-trees-in-almost-polynomial-time",title:"Properly learning decision trees in almost polynomial time",description:"learning a decision tree for unifrom random data distribution in O(s ^ log(log(s)))",section:"Summaries",handler:()=>{window.location.href="/summaries/Properly_learning-_decision_trees_in_almost_polynomial_time/"}},{id:"summaries-scaling-monosemanticity-extracting-interpretable-features-from-claude-3-sonnet",title:"Scaling Monosemanticity Extracting Interpretable Features from Claude 3 Sonnet",description:"Scale SAE to Claude 3 Sonnet",section:"Summaries",handler:()=>{window.location.href="/summaries/Scaling_Monosemanticity_Extracting_Interpretable_Features_from_Claude_3_Sonnet/"}},{id:"summaries-top-down-induction-of-decision-trees-rigorous-guarantees-and-inherent-limitations",title:"Top-down induction of decision trees- rigorous guarantees and inherent limitations",description:"greedily learn a decision tree based on the most inflouential variables in all leaves.",section:"Summaries",handler:()=>{window.location.href="/summaries/Top_down_induction_of_decision_trees_rigorous_guarantees_and_inherent_limitations/"}},{id:"summaries-towards-monosemanticity-decomposing-language-models-with-dictionary-learning",title:"Towards Monosemanticity Decomposing Language Models With Dictionary Learning",description:"How SAE works",section:"Summaries",handler:()=>{window.location.href="/summaries/Towards_Monosemanticity_Decomposing_Language_Models_With_Dictionary_Learning/"}},{id:"summaries-what-do-we-learn-from-inverting-clip-models",title:"What do we learn from inverting CLIP models?",description:"summary of What do we learn from inverting CLIP models?",section:"Summaries",handler:()=>{window.location.href="/summaries/What_do_we_learn_from_inverting_CLIP_models/"}},{id:"summaries-zoom-in-an-introduction-to-circuits",title:"Zoom In An Introduction to Circuits",description:"Investigate Vision Circuits by Studying the Connections between Neurons",section:"Summaries",handler:()=>{window.location.href="/summaries/Zoom_In_An_Introduction_to_Circuits/"}},{id:"summaries-active-learning-survey",title:"Active Learning Survey",description:"Active Learning for Agnostic classification",section:"Summaries",handler:()=>{window.location.href="/summaries/active-survey/"}},{id:"summaries-the-true-sample-complexity-of-active-learning",title:"The True Sample Complexity of Active Learning",description:"A different definition of active learning label complexity",section:"Summaries",handler:()=>{window.location.href="/summaries/true-active/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61%72%73%68%69%61.%73%6F%6C%74%61%6E%69%32@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=2H6Wl4MAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/ckodser","_blank")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>