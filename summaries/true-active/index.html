<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The True Sample Complexity of Active Learning | Arshia Soltani Moakhar </title> <meta name="author" content="Arshia Soltani Moakhar"> <meta name="description" content="A different definition of active learning label complexity"> <meta name="keywords" content="academic-website, research, Arshia Soltani Moakhar, ckodser, adversarial training, OOD detection, Interpretability"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon3.ico?ed0664bb8b662bf21b84ddd264d8c2a9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ckodser.github.io/summaries/true-active/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class=" sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="//"> <span class="font-weight-bold">Arshia</span> Soltani Moakhar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item active"> <a class="nav-link" href="/summaries/">Summaries <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The True Sample Complexity of Active Learning</h1> <p class="post-description">A different definition of active learning label complexity</p> <a href="https://www.cs.cmu.edu/~ninamf/papers/true-active.pdf" class="btn btn-primary" target="_blank" rel="noopener noreferrer">Link</a> </header> <article> <p>This 2010 paper have these important results under the realizable case (When the best classifier is perfect):</p> <p>We see a sharp distinction between the sample complexity required to find a good classifier (logarithmic) and the sample complexity needed to both find a good classifier and verify that it is good. (Section 1 example)</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/true-active/img_1.png" sizes="95vw"></source> <img src="/assets/img/true-active/img_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>They say definition 2 is a lot easier than definition 1. Definition 1 is equivalent to the case that algorithm return the classifier after some point. Meaning it knows it found a good classifier. In Definition 2 the algorithm suggests classifier at each step that after a certain point is guaranteed to be good. That point however is unknown to the algorithm. We might be able to find an upper bound on the maximum number of labels so that the algorithm found a good classifier using quantities unknown to the algorithm, for example properties of the label distribution.</p> <h1> With Definition 1 </h1> <p>Passive learning is known to achieve bound \(O((\frac{d}{\epsilon}) log(\frac{1}{\epsilon}) + (\frac{1}{\epsilon}) log(\frac{1}{\delta}))\).</p> <p>The hope is to find active learning algorithms that achieve the polylog \(\frac{1}{\epsilon}\) bound. However in many simple cases it has been shown that one need at least \(\frac{1}{\epsilon}\) labels to find a good classifier.</p> <p>The bound that active learning (CAL) algorithms achieve is as follows:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/true-active/img_2.png" sizes="95vw"></source> <img src="/assets/img/true-active/img_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>The label complexity is \(\theta_{h^*}.d.polylog(1/(\epsilon \delta))\), where when run with concept class \(C\) for target function \(h^*\in C\).</p> <h1> With Definition 2 </h1> <p>In particular, we show that many common cases have sample complexity that is polylogarithmic in both \(\frac{1}{\epsilon}\) and \(\frac{1}{\delta}\) and linear only in some finite target dependent constant \(\gamma_{h^*}\). This contrasts sharply with the infamous \(\frac{1}{\epsilon}\) lower bounds mentioned above, which have been identified for verifiable sample complexity.</p> <p>With this definition their goal is to achieve polylog bounds on \(\frac{1}{\epsilon}\) and \(\frac{1}{\delta}\) but potentially linear in \(\gamma_{h^*}\).</p> <h2> With Definition 2 Active learning is always good</h2> <p>With definition 1 we know that we have a lower bound of \(\frac{1}{\epsilon}\), however, they show that with definition 2 have a label complexity of \(o(\frac{1}{\epsilon})\).</p> <p>Corollary 7. For any \(C\) with finite VC dimension, and any distribution \(D\) over \(X\), there is an active learning algorithm that achieves a sample complexity \(S(\epsilon, \delta, h)\) such that \(S(\epsilon, \delta, h)\) = \(o(\frac{1}{\epsilon})\) for all targets \(h \in C\).</p> <h1> Composing Hypothesis Classes </h1> <p>Assume we have groups of classifiers \(C_1, C_2, \ldots, C_\infty\), and we for each of these groups we have an active learning algorithm that finds a good classifier in \(C_i\) if the optimal classifier is in \(C_i\). The question is how can we merge these algorithms to find a good classifier in \(C\)?</p> <p>They provide an algorithm that does this. This is the resulting label complexity.</p> <p>Theorem 8 For any distribution \(D\), let \(C_1, C_2, \ldots\) be a sequence of classes such that for each \(i\), the pair \((C_i, D)\) has sample complexity at most \(S_i(\epsilon, \delta, h)\) for all \(h \in C_i\). Let \(C = \bigcup_{i=1}^\infty C_i\). Then \((C, D)\) has a sample complexity at most</p> \[\min_{i:h \in C_i} \max \{ 4i^2S_i(\frac{\epsilon}{2}, \frac{\delta}{2}, h), 2i^2 72 \ln(\frac{4i}{\delta})\}\] <p>for any \(h\in C\). In particular, Algorithm 1 achieves this, when used with the \(A_i\) algorithms that each achieve the \(S_i(\epsilon, \delta, h)\) sample complexity. This is cool since if we have a algorithm fro each \(A_i\) that is polylog in \(\frac{1}{\epsilon}\) and \(\frac{1}{\delta}\) then their combination would be polylog.</p> <p>Then they prove a very important and cool theorem. They show that the reverse is also correct. They show that is we have a algorithm that is polylog with definition 2, then we can break the classifier space in a \(C_1, C_2, \ldots\) sequence, that each of \(C_i\) has a polylog algorithm with definition 1 (verifiable active learning).</p> <p>Theorem 9 For any \((C, D)\) learnable at an exponential rate, there exists a sequence \(C_1, C_2, \ldots\) with \(C = \bigcup_{i=1}^\infty C_i\) , and a sequence of active learning algorithms \(A_1, A_2, \ldots\) such that the algorithm \(A_i\) achieves verifiable sample complexity at most \(\gamma_i polylog_i(\frac{1}{\epsilon\delta})\) for the pair \((C_i, D)\). Thus, the aggregation algorithm (Algorithm 1) achieves exponential rates when used with these algorithms.</p> <h1> Exponential Rates </h1> <p>Some example that Exponential Rates are achievable.</p> <ol> <li>Unions of k intervals. for example for k=2 we have classifier that classifies [0.1,0.3] and [0.5,0.7] as + and other points as -. They show that something like this has a disagreement coefficient of \(k+\frac{1}{w(h)}\).</li> <li>Ordinary Binary Classification Trees: Let \(X\) be the cube \([0,1]^n\), \(D\) be the uniform distribution on \(X\), and \(C\) be the class of binary decision trees using a finite number of axis parallel splits.</li> <li>Linear Separators</li> </ol> <h2> Composition results</h2> <ol> <li>They show that if you can achieve a polylog label complexity on some distribution \(D\), you can achieve it in a close distribution \(D'\) such that \(\frac{1}{\lambda}D(A)\leq D'(A) \leq \lambda D(A)\) for some \(\lambda\) and all \(A\).</li> <li>They show that if you can achieve a polylog label complexity on \(D_1\) and \(D_2\), you can achieve polylog label complexity on the linear combinations of them.</li> </ol> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"ckodser/ckodser.github.io","data-repo-id":"R_kgDOHfm8sw","data-category":"General","data-category-id":"DIC_kwDOHfm8s84ClE4O","data-mapping":"pathname","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":"light","data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © 2025 Arshia Soltani Moakhar. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"My Research Projects",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"repositories",description:"Repositories to which I&#39;m a major contributor. Most of these works were done as a course final project.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-summaries",title:"Summaries",description:"Paper summaries",section:"Navigation",handler:()=>{window.location.href="/summaries/"}},{id:"projects-data-leakage-of-lora-in-federated-training",title:"Data Leakage of LoRA in federated training",description:"This article highlights the potential risks of reconstructing private data from the gradients shared in Federated Learning, especially when using the LoRA finetuning technique.",section:"Projects",handler:()=>{window.location.href="/projects/Attention_is_all_you_need_to_attack/"}},{id:"projects-basedon",title:"BasedOn",description:"Using Learnable If Statements for Interpretability",section:"Projects",handler:()=>{window.location.href="/projects/BasedOn/"}},{id:"projects-sparsity-for-interpretability",title:"sparsity for interpretability",description:"Leveraging sample sparsity to improve interpretability of neural networks",section:"Projects",handler:()=>{window.location.href="/projects/SPADE/"}},{id:"projects-certified-robust-neural-network",title:"Certified Robust Neural Network",description:"Certify Robustness using median neurons",section:"Projects",handler:()=>{window.location.href="/projects/sparse_L_inf_network/"}},{id:"summaries-a-mathematical-framework-for-transformer-circuits",title:"A Mathematical Framework for Transformer Circuits",description:"In Transformers residual stream is the main object and layers read and write from/to it.",section:"Summaries",handler:()=>{window.location.href="/summaries/A_Mathematical_Framework_for_Transformer_Circuits/"}},{id:"summaries-an-overview-of-early-vision-in-inceptionv1",title:"An Overview of Early Vision in InceptionV1",description:"inceptionV1 feature maps of different layers",section:"Summaries",handler:()=>{window.location.href="/summaries/An_Overview_of_Early_Vision_in_InceptionV1/"}},{id:"summaries-clip-dissect-automatic-description-of-neuron-representations",title:"CLIP-Dissect Automatic Description of Neuron Representations",description:"Find concepts that activates a neuron using a image dataset",section:"Summaries",handler:()=>{window.location.href="/summaries/CLIP-Dissect_Automatic_Description_of_Neuron_Representations_in_Deep_Vision_Networks/"}},{id:"summaries-can-large-language-models-explain-their-internal-mechanisms",title:"Can Large Language Models Explain Their Internal Mechanisms?",description:"summary of Can Large Language Models Explain Their Internal Mechanisms?",section:"Summaries",handler:()=>{window.location.href="/summaries/Can_Large_Language_Models_Explain_Their_Internal_Mechanisms/"}},{id:"summaries-emergent-world-representations-exploring-a-sequence-model-trained-on-a-synthetic-task",title:"Emergent World Representations Exploring a Sequence Model Trained on a Synthetic Task",description:"summary of Emergent World Representations  Exploring a Sequence Model Trained on a Synthetic Task",section:"Summaries",handler:()=>{window.location.href="/summaries/Emergent_World_Representations_Exploring_a_Sequence_Model_Trained_on_a_Synthetic_Task/"}},{id:"summaries-interpretability-beyond-feature-attribution-quantitative-testing-with-concept-activation-vectors-tcav",title:"Interpretability Beyond Feature Attribution Quantitative Testing with Concept Activation Vectors (TCAV)",description:"summary of Interpretability Beyond Feature Attribution  Quantitative Testing with Concept Activation Vectors (TCAV)",section:"Summaries",handler:()=>{window.location.href="/summaries/Interpretability_Beyond_Feature_Attribution_Quantitative_Testing_with_Concept_Activation_Vectors_(TCAV)/"}},{id:"summaries-labeling-neural-representations-with-inverse-recognition",title:"Labeling Neural Representations with Inverse Recognition",description:"summary of Labeling Neural Representations with Inverse Recognition",section:"Summaries",handler:()=>{window.location.href="/summaries/Labeling_Neural_Representations_with_Inverse_Recognition/"}},{id:"summaries-leveraged-volume-sampling-for-linear-regression",title:"Leveraged volume sampling for linear regression",description:"Active Learning in linear regression with multiplicative error rate bounds",section:"Summaries",handler:()=>{window.location.href="/summaries/Leveraged_volume_sampling_for_linear_regression/"}},{id:"summaries-progress-measures-for-grokking-via-mechanistic-interpretability",title:"Progress measures for grokking via mechanistic interpretability",description:"summary of Progress measures for grokking via mechanistic interpretability",section:"Summaries",handler:()=>{window.location.href="/summaries/Progress_measures_for_grokking_via_mechanistic_interpretability/"}},{id:"summaries-scaling-monosemanticity-extracting-interpretable-features-from-claude-3-sonnet",title:"Scaling Monosemanticity Extracting Interpretable Features from Claude 3 Sonnet",description:"Scale SAE to Claude 3 Sonnet",section:"Summaries",handler:()=>{window.location.href="/summaries/Scaling_Monosemanticity_Extracting_Interpretable_Features_from_Claude_3_Sonnet/"}},{id:"summaries-towards-monosemanticity-decomposing-language-models-with-dictionary-learning",title:"Towards Monosemanticity Decomposing Language Models With Dictionary Learning",description:"How SAE works",section:"Summaries",handler:()=>{window.location.href="/summaries/Towards_Monosemanticity_Decomposing_Language_Models_With_Dictionary_Learning/"}},{id:"summaries-what-do-we-learn-from-inverting-clip-models",title:"What do we learn from inverting CLIP models?",description:"summary of What do we learn from inverting CLIP models?",section:"Summaries",handler:()=>{window.location.href="/summaries/What_do_we_learn_from_inverting_CLIP_models/"}},{id:"summaries-zoom-in-an-introduction-to-circuits",title:"Zoom In An Introduction to Circuits",description:"Investigate Vision Circuits by Studying the Connections between Neurons",section:"Summaries",handler:()=>{window.location.href="/summaries/Zoom_In_An_Introduction_to_Circuits/"}},{id:"summaries-active-learning-survey",title:"Active Learning Survey",description:"Active Learning for Agnostic classification",section:"Summaries",handler:()=>{window.location.href="/summaries/active-survey/"}},{id:"summaries-the-true-sample-complexity-of-active-learning",title:"The True Sample Complexity of Active Learning",description:"A different definition of active learning label complexity",section:"Summaries",handler:()=>{window.location.href="/summaries/true-active/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61%72%73%68%69%61.%73%6F%6C%74%61%6E%69%32@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/ckodser","_blank")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>